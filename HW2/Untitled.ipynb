{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import numpy as np\n",
    "import math\n",
    "import sys\n",
    "import random\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "M =  full with stop words  error rate: 0.21892071952\n",
    "\n",
    "M =  full without stop words  error rate: 0.199200532978\n",
    "\n",
    "M =  20000 random error rate: 0.30726182545\n",
    "\n",
    "M =  10000 random error rate: 0.409593604264\n",
    "\n",
    "M =  5000  error rate: 0.564956695536\n",
    "\n",
    "### Top and log(1+f)\n",
    "\n",
    "M =  20000  error rate: 0.20266489007328448\n",
    "\n",
    "M =  10000  error rate: 0.220386409061 \n",
    "\n",
    "M =  5000  error rate: 0.25076615589606926\n",
    "\n",
    "### Random without removing stop words\n",
    "\n",
    "M = 5000 mean 0.543730846102 std 0.0129676478143"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "directory = \"/Users/liuxiyun/Dropbox/Study/16fall/CSE250B/Hw2/20news-bydate_parse/matlab/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def readData(name):\n",
    "    with open(directory + name) as f:\n",
    "        content = [[int(num) for num in x.strip('\\n').split(\" \")] for x in f.readlines()]\n",
    "    print len(content),\n",
    "    return content\n",
    "def readLabel(name):\n",
    "    with open(directory + name) as f:\n",
    "        content = [int(num) for num in f.readlines()]\n",
    "    print len(content),\n",
    "    return content\n",
    "def readMap(name):\n",
    "    d = {}\n",
    "    with open(directory + name) as f:\n",
    "        for line in f:\n",
    "           (val, key) = line.split()\n",
    "           d[int(key)] = val\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1467345 11269 967874 7505\n"
     ]
    }
   ],
   "source": [
    "trainData = readData('train.data')\n",
    "trainLabel = readLabel('train.label')\n",
    "testData = readData('test.data')\n",
    "testLabel = readLabel('test.label')\n",
    "trainMap = readMap('train.map')\n",
    "testMap = readMap('test.map')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"/Users/liuxiyun/Dropbox/Study/16fall/CSE250B/Hw2/vocabulary.txt\") as f:\n",
    "    vocabulary = [x.strip('\\n') for x in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11269 61188 20 7505\n"
     ]
    }
   ],
   "source": [
    "numDoc = len(trainLabel)\n",
    "numVoc = len(vocabulary)\n",
    "numClass = 20\n",
    "numTest = len(testLabel)\n",
    "print numDoc,numVoc,numClass,numTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainX = np.zeros((numDoc, numVoc))\n",
    "testX = np.zeros((len(testLabel), numVoc))\n",
    "for wordInfo in trainData:\n",
    "    trainX[wordInfo[0]-1][wordInfo[1]-1] = wordInfo[2]\n",
    "for wordInfo in testData:\n",
    "    testX[wordInfo[0]-1][wordInfo[1]-1] = wordInfo[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rawIdxList = [num for num in range(0,numVoc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pi = [trainLabel.count(label)*1.0/numDoc for label in range(1,21)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get stop words' index \n",
    "stopWords = [str(x) for x in stopwords.words(\"english\")]\n",
    "stopWordsIdx = []\n",
    "for stopWords in stopWords:\n",
    "    if stopWords in set(vocabulary):\n",
    "        stopWordsIdx.append(vocabulary.index(stopWords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Pjw\n",
    "eachClassWordCount = np.ones((20,numVoc)) # 1 for smoothing\n",
    "for i in range(0,len(trainData)):\n",
    "    docId = trainData[i][0]\n",
    "    wordId = trainData[i][1]\n",
    "    wordCount = trainData[i][2]\n",
    "    docLabel = trainLabel[docId-1]\n",
    "    eachClassWordCount[docLabel-1][wordId-1] += wordCount\n",
    "\n",
    "numTotalWordCount = zip(np.sum(eachClassWordCount, axis = 0),rawIdxList)\n",
    "numTotalWordCount.sort(key = lambda x:x[0],reverse = True)\n",
    "topCountWordIdx = map(lambda x:x[1], numTotalWordCount)\n",
    "topCountWordIdxRemoveStop = filter(lambda x: x not in set(stopWordsIdx),topCountWordIdx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predictThisDoc(pjw,docWordCount):\n",
    "    maxProb = -sys.maxint - 1\n",
    "    guessClass = 0\n",
    "    logPi = np.log(pi)\n",
    "    logPjw = np.log(pjw)\n",
    "    for groupId in range(0, numClass):\n",
    "        p = logPi[groupId]\n",
    "        for word in range(0,len(docWordCount)):\n",
    "            p += docWordCount[word]*logPjw[groupId][word]\n",
    "        if p > maxProb:\n",
    "            maxProb = p\n",
    "            guessClass = groupId+1\n",
    "    return guessClass\n",
    "def predictThisDocNotLog(pjw,docWordCount):\n",
    "    maxProb = -sys.maxint - 1\n",
    "    guessClass = 0\n",
    "    for groupId in range(0, numClass):\n",
    "        p = pi[groupId]\n",
    "        for word in range(0,len(docWordCount)):\n",
    "            p += docWordCount[word]*math.log(pjw[groupId][word])\n",
    "        if p > maxProb:\n",
    "            maxProb = p\n",
    "            guessClass = groupId\n",
    "    return guessClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generatePJWAndTestX(M, eachClassWordCount, testX):\n",
    "#     randIdx = randomSubVocab(M)\n",
    "#     idxRandomNeedRemove  = filter(lambda x: x not in set(randIdx), rawIdxList)\n",
    "#     idxNeedRemove = list(set(idxRandomNeedRemove + stopWordsIdx))\n",
    "\n",
    "    idxNeedRemove = list(set( topCountWordIdxRemoveStop[M:]+ stopWordsIdx))\n",
    "    filteredEachClassWordCount = np.delete(eachClassWordCount, idxNeedRemove, axis = 1)\n",
    "    filteredTestX = np.delete(testX, idxNeedRemove, axis = 1)\n",
    "    filteredEachClassWordCountLog = np.log(1+filteredEachClassWordCount)\n",
    "    numWordInClass = np.sum(filteredEachClassWordCountLog, axis = 1)\n",
    "    pjw = filteredEachClassWordCount/numWordInClass[:,None]\n",
    "    \n",
    "\n",
    "    return pjw, filteredTestX\n",
    "def generatePJWAndTestXNotLog(M, eachClassWordCount, testX):\n",
    "    idxNeedRemove = list(set( topCountWordIdxRemoveStop[M:]+ stopWordsIdx))\n",
    "    filteredEachClassWordCount = np.delete(eachClassWordCount, idxNeedRemove, axis = 1)\n",
    "    filteredTestX = np.delete(testX, idxNeedRemove, axis = 1)\n",
    "    numWordInClass = np.sum(filteredEachClassWordCount, axis = 1)\n",
    "    pjw = filteredEachClassWordCount/numWordInClass[:,None]\n",
    "\n",
    "    return pjw, filteredTestX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "numWordInClass = np.sum(eachClassWordCount, axis = 1)\n",
    "pjw = eachClassWordCount/numWordInClass[:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test(M):\n",
    "    filteredPJW, filteredTestX = generatePJWAndTestXNotLog(M, eachClassWordCount, testX)\n",
    "    print len(filteredPJW[1])\n",
    "    error= 0\n",
    "    i = 0\n",
    "    for i in range(len(filteredTestX)):\n",
    "        predictLabel = predictThisDoc(filteredPJW, filteredTestX[i])\n",
    "        if predictLabel!= testLabel[i]:\n",
    "            error += 1\n",
    "    error_rate = error* 1.0 / len(filteredTestX)\n",
    "    print \"M =\", M,\" error_rate:\" + str(error_rate)\n",
    "    return error_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n",
      "M = 5000  error_rate:0.250766155896\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.25076615589606926"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "M = 10000  error_rate:0.220386409061\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.22038640906062626"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000\n",
      "M = 20000  error_rate:0.202664890073\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.20266489007328448"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def randomSubVocab(M):\n",
    "    randomIdx = random.sample(range(0, numVoc), M)\n",
    "    return randomIdx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M = 61188  error_rate:0.21894989339\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.21894989339019189"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Full vocab\n",
    "test(numVoc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getNewX(removedIdx, train = trainX, test = testX):\n",
    "    newTrainX = np.delete(train, removedIdx, axis = 1)\n",
    "    newTestX = np.delete(test, removedIdx, axis = 1)\n",
    "    return newTrainX, newTestX\n",
    "\n",
    "def randomSubVocIdx(M, fullIdx):\n",
    "    randomIdx = random.sample(range(0, len(fullIdx)), M)\n",
    "    subsetIdxList = [fullIdx[i] for i in randomIdx]\n",
    "    return subsetIdxList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def testUsingLib(trainX,testX,M):\n",
    "    clf = MultinomialNB()\n",
    "    clf.fit(trainX,np.array(trainLabel))#Target values.\n",
    "    MultinomialNB(alpha=1, class_prior=None, fit_prior=True)\n",
    "    predictLabel = clf.predict(testX)\n",
    "    errorRate = len(filter(lambda x: x[0] != x[1],zip(predictLabel,testLabel)))*1.0/numTest\n",
    "    print \"M = \", M, \" error rate:\",errorRate,\"this is me\"\n",
    "    return errorRate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M =  full with stop words  error rate: 0.21892071952\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ 1,  1,  1, ...,  1, 16,  2]), 0.21892071952031977)"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testUsingLib(trainX,testX,'full with stop words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M =  full without stop words  error rate: 0.199200532978\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ 1,  1,  1, ...,  1, 16,  2]), 0.19920053297801465)"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newTrainX, newTestX = getNewX(stopWordsIdx)\n",
    "testUsingLib(newTrainX,newTestX, 'full without stop words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def randomSelectSubsetTest(M, trainX = trainX,testX = testX):\n",
    "    idxWithoutStopWords = filter(lambda x: x not in stopWordsIdx, [i for i in range(0,numVoc)])\n",
    "    randomIdx = set(randomSubVocIdx(M, [i for i in range(0,numVoc)]))\n",
    "    idxNeedRemove = filter(lambda x: x not in randomIdx, [i for i in range(0,numVoc)])\n",
    "    newTrainX, newTestX = getNewX(idxNeedRemove,trainX,testX)\n",
    "    return testUsingLib(newTrainX,newTestX, M)\n",
    "\n",
    "def selectTopWordsTest(M, trainX = trainX,testX = testX):\n",
    "    idxNeedRemove = list(set(topCountWordIdxRemoveStop[M:]+ stopWordsIdx))\n",
    "    newTrainX, newTestX = getNewX(idxNeedRemove,trainX,testX)\n",
    "    return testUsingLib(newTrainX,newTestX, M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M =  20000  error rate: 0.318321119254\n",
      "M =  20000  error rate: 0.341505662891\n",
      "M =  20000  error rate: 0.337375083278\n",
      "M =  20000  error rate: 0.328181212525\n",
      "M =  20000  error rate: 0.32871419054\n",
      "M =  20000  error rate: 0.338840772818\n",
      "M =  20000  error rate: 0.330446369087\n",
      "M =  20000  error rate: 0.322318454364\n",
      "M =  20000  error rate: 0.319920053298\n",
      "M =  20000  error rate: 0.327514990007\n"
     ]
    }
   ],
   "source": [
    "randomTwentyThousand = []\n",
    "for i in range(0,10):\n",
    "    randomTwentyThousand.append(randomSelectSubsetTest(20000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.329313790806\n",
      "0.00754033224474\n"
     ]
    }
   ],
   "source": [
    "print np.mean(randomTwentyThousand)\n",
    "print np.std(randomTwentyThousand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M =  10000  error rate: 0.44836775483\n",
      "M =  10000  error rate: 0.440772818121\n",
      "M =  10000  error rate: 0.436109260493\n",
      "M =  10000  error rate: 0.441838774151\n",
      "M =  10000  error rate: 0.435842771486\n",
      "M =  10000  error rate: 0.425183211193\n",
      "M =  10000  error rate: 0.408261159227\n",
      "M =  10000  error rate: 0.432511658894\n",
      "M =  10000  error rate: 0.427981345769\n",
      "M =  10000  error rate: 0.420919387075\n",
      "0.431778814124\n",
      "0.0110545168399\n"
     ]
    }
   ],
   "source": [
    "randomTenThousand = []\n",
    "for i in range(0,10):\n",
    "    randomTenThousand.append(randomSelectSubsetTest(10000))\n",
    "print np.mean(randomTenThousand)\n",
    "print np.std(randomTenThousand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.44836775483011326, 0.4407728181212525, 0.4361092604930047, 0.44183877415056627, 0.43584277148567624, 0.4251832111925383, 0.40826115922718187, 0.4325116588940706, 0.427981345769487, 0.42091938707528315]\n"
     ]
    }
   ],
   "source": [
    "print randomTenThousand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "randomFiveThousand = [0.5530979347,0.559360426382,0.520319786809,0.549500333111,0.518854097268,0.543904063957,0.552831445703,0.550566289141,0.547501665556,0.541372418388]\n",
    "# for i in range(0,10):\n",
    "#     randomFiveThousand.append(randomSelectSubsetTest(5000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.543730846102\n",
      "0.0129676478143\n"
     ]
    }
   ],
   "source": [
    "print np.mean(randomFiveThousand)\n",
    "print np.std(randomFiveThousand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M =  5000  error rate: 0.546702198534\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5467021985343105"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randomSelectSubsetTest(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pjwStd = []\n",
    "pjwMean = []\n",
    "for i in range(0,numVoc):\n",
    "    pjwStd.append(np.std(pjw[:,i]))\n",
    "    pjwMean.append(np.mean(pjw[:,i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stdWithIdx = zip(pjwStd,rawIdxList)\n",
    "stdWithIdx.sort(key = lambda x: x[0])\n",
    "stdWithIdx = filter(lambda x: x[1] not in set(stopWordsIdx),stdWithIdx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def selectSubsetByStd(M):\n",
    "    subsetIdx = map(lambda (std,idx): idx, stdWithIdx)[:M]\n",
    "    idxNeedRemove = filter(lambda x: x not in subsetIdx, [i for i in range(0,numVoc)])\n",
    "    newTrainX, newTestX = getNewX(idxNeedRemove)\n",
    "    testUsingLib(newTrainX,newTestX, M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M =  20000  error rate: 0.701132578281\n"
     ]
    }
   ],
   "source": [
    "selectSubsetByStd(20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.034637029928602091"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(pjwMean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logTrainX = np.log2(trainX+1)\n",
    "logTestX = np.log2(testX+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M =  20000  error rate: 0.301265822785\n"
     ]
    }
   ],
   "source": [
    "randomSelectSubsetTest(20000,logTrainX,logTestX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M =  10000  error rate: 0.38654230513\n"
     ]
    }
   ],
   "source": [
    "randomSelectSubsetTest(10000,logTrainX,logTestX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M =  5000  error rate: 0.532311792139\n"
     ]
    }
   ],
   "source": [
    "randomSelectSubsetTest(5000,logTrainX,logTestX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[1,2],[3,4]])\n",
    "a[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M =  15000  error rate: 0.206928714191 this is me\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.20692871419053965"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selectTopWordsTest(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M =  10000  error rate: 0.220386409061 this is me\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.22038640906062626"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selectTopWordsTest(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M =  20000  error rate: 0.202664890073 this is me\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.20266489007328448"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selectTopWordsTest(20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 6])"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[1,2],[3,4]])\n",
    "np.sum(a,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "topOneThousand = topCountWordIdxRemoveStop[:1000]\n",
    "subsetVoc = []\n",
    "for idx in topOneThousand:\n",
    "    subsetVoc.append(vocabulary[idx])\n",
    "probOfWordAmongClasses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "totalWordCountInEachClass = np.sum(eachClassWordCount,axis = 0)\n",
    "probWordInClass = eachClassWordCount/totalWordCountInEachClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wordBelongsClass = np.argmax(probWordInClass, axis=0)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "classWord = collections.defaultdict(list)\n",
    "for idx in topOneThousand:\n",
    "    if len(classWord[wordBelongsClass[idx]])>=30:\n",
    "        continue\n",
    "    else:\n",
    "        classWord[wordBelongsClass[idx]].append(vocabulary[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['new', 'please', 'interested', 'price', 'original', 'sell', 'includes', 'offer', 'sale', 'cover', 'included', 'ii', 'asking', 'condition', 'appears', 'excellent', 'manual', 'shipping']\n"
     ]
    }
   ],
   "source": [
    "print classWord[7\n",
    "               ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
